{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_fedbert.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_VEAbGqVletS","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Check availble memory of GPU\n","# Check that we are using 100% of GPU\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip -q install gputil\n","!pip -q install psutil\n","!pip -q install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbjCaEdolTzw","colab_type":"code","colab":{}},"source":["!pip install -qq transformers\n","!pip install -qq nlp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AUMNVmjluPo","colab_type":"code","colab":{}},"source":["# imports\n","from transformers import (\n","    BertForMaskedLM,\n","    BertTokenizer,\n","    BertConfig,\n","    Trainer,\n","    DataCollatorForLanguageModeling,\n","    TrainingArguments,\n","    LineByLineTextDataset,\n",")\n","import torch\n","from torch.utils.data.dataset import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eu9NHxTvdZxO","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qsyJ5663cSC","colab_type":"code","colab":{}},"source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n","\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"/content/drive/My Drive/230T2 MLTS/Colab Notebooks/data/sifted_Speech.txt\",\n","    block_size=128,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0BoKyBXsYdX","colab_type":"code","colab":{}},"source":["pretrain = 'FIN'\n","if pretrain == 'BERT':\n","    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","elif pretrain =='FIN':\n","    model = BertForMaskedLM.from_pretrained('/content/drive/My Drive/230T2 MLTS/Colab Notebooks/params/FinBERT-Prime_128MSL-250K')\n","else:\n","    config = BertConfig()\n","    model = BertForMaskedLM(config)\n","model = model.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffShBXVisaW3","colab_type":"code","colab":{}},"source":["training_args = {\n","    \"output_dir\": \"/content/drive/My Drive/230T2 MLTS/Colab Notebooks/params/\"+pretrain,\n","    \"overwrite_output_dir\": True,\n","    \"logging_dir\": \"/content/drive/My Drive/230T2 MLTS/Colab Notebooks/params/logs\",\n","    \"learning_rate\": 1e-4,\n","    \"do_train\": True,\n","    \"do_eval\": True,\n","    \"max_steps\": 5000,\n","    # \"num_train_epochs\":1,\n","    \"warmup_steps\": 100,\n","    \"weight_decay\": 0.001,\n","    \"per_device_train_batch_size\": 16,\n","    \"per_device_eval_batch_size\": 4,\n","    \"logging_steps\": 200,\n","    \"fp16\": True,\n","    \"save_steps\": 500,\n","}\n","\n","training_args = TrainingArguments(**training_args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UiTC7EZkvOZV","colab_type":"code","colab":{}},"source":["# create the trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset\n",")\n","\n","# train\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4lJ_0Wc3uKu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}