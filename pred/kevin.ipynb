{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model            = {}\n",
    "model['GooBERT'] = BertForMaskedLM.from_pretrained('./GooBERT')\n",
    "model['FinBERT'] = BertForMaskedLM.from_pretrained('FinBERT-Prime_128MSL-250K')\n",
    "model['PreBERT'] = BertForMaskedLM.from_pretrained('FinBERT-Pre2K_128MSL-250K')\n",
    "model['ComBERT'] = BertForMaskedLM.from_pretrained('FinBERT-Combo_128MSL-250K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 [CLS]\n1 market\n2 conditions\n3 have\n4 improved\n5 since\n6 the\n7 2007\n8 -\n9 2009\n10 recession\n11 .\n12 [SEP]\n13 conditions\n14 remain\n15 challenging\n16 for\n17 financial\n18 institutions\n19 .\n20 [SEP]\n['[CLS]', 'market', 'conditions', 'have', 'improved', 'since', 'the', '2007', '-', '2009', 'recession', '.', '[SEP]', 'conditions', 'remain', 'challenging', 'for', 'financial', 'institutions', '.', '[SEP]']\n"
    }
   ],
   "source": [
    "# Fed\n",
    "S1 = '[CLS] the company has a fiduciary duty to its shareholders . [SEP]'\n",
    "S2 = 'one of its many regulatory requirements . [SEP]'\n",
    "\n",
    "# Fin\n",
    "S1 = '[CLS] market conditions have improved since the 2007-2009 recession . [SEP]'\n",
    "S2 = 'conditions remain challenging for financial institutions . [SEP]'\n",
    "\n",
    "tokenizer      = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text           = f'{S1} {S2}'\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "for i, word in enumerate(tokenized_text):\n",
    "    print(\"{} {}\".format(i, word))\n",
    "    \n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['[CLS]', 'market', 'conditions', 'have', 'improved', 'since', 'the', '2007', '-', '2009', '[MASK]', '.', '[SEP]', 'conditions', '[MASK]', 'challenging', 'for', 'financial', 'institutions', '.', '[SEP]']\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\nGooBERT\n1th most likely recession\n2th most likely period\n3th most likely season\n4th most likely crisis\n5th most likely year\n\nFinBERT\n1th most likely recession\n2th most likely crisis\n3th most likely period\n4th most likely attacks\n5th most likely hurricanes\n\nPreBERT\n1th most likely period\n2th most likely season\n3th most likely fires\n4th most likely deadline\n5th most likely seasons\n\nComBERT\n1th most likely recession\n2th most likely period\n3th most likely crisis\n4th most likely peak\n5th most likely time\n\nGooBERT : ['recession', 'are']\nFinBERT : ['recession', 'remain']\nPreBERT : ['period', 'are']\nComBERT : ['recession', 'remain']\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "MI = [10, 14]\n",
    "\n",
    "for i in MI :\n",
    "    tokenized_text[i] = '[MASK]'\n",
    "\n",
    "print(tokenized_text)\n",
    "\n",
    "indexed_tokens   = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids     = [0] * len(tokenizer.tokenize(S1)) + [1] * len(tokenizer.tokenize(S2))\n",
    "\n",
    "print(segments_ids)\n",
    "\n",
    "tokens_tensor    = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "preds  = {}\n",
    "for m in model:\n",
    "    with torch.no_grad():\n",
    "        preds[m] = model[m](tokens_tensor, token_type_ids = segments_tensors)[0]\n",
    "        predicted_index = torch.argmax(preds[m][0, 14]).item()\n",
    "        predicted_indecies = np.argsort((preds[m][0, 10]))\n",
    "        print(m)\n",
    "        for i in range(1, 6):\n",
    "            print(f'{i}th most likely {tokenizer.convert_ids_to_tokens([predicted_indecies[-i].item()])[0]}')\n",
    "        print(\"\")\n",
    "        \n",
    "for m in preds:\n",
    "    tokens = []\n",
    "    for i in MI:\n",
    "        predicted_index = torch.argmax(preds[m][0, i]).item()\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "        tokens.append(predicted_token)\n",
    "\n",
    "    print(f'{m} : {tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive examples have better results in Fin, negative Goo performs better.  Financial documents accentuate the positive?\n",
    "\n",
    "Finbert feels \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}